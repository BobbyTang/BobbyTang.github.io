
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>BobbyTang Blog</title>
  <meta name="author" content="BobbyTang">

  
  <meta name="description" content="This post intend to write down the step for installing ruby and vim command line tools, without root access.
In addition, ncurses is the &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://BobbyTang.github.io">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/atom.xml" rel="alternate" title="BobbyTang Blog" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="./javascripts/libs/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  

</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">BobbyTang Blog</a></h1>
  
    <h2>Share more, Gain more.</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:BobbyTang.github.io" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2014/05/30/install-ruby-and-vim-command-without-root/">Install Ruby&amp;Vim Command Without Root</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-05-30T08:17:24+08:00" pubdate data-updated="true">May 30<span>th</span>, 2014</time>
        
           | <a href="/blog/2014/05/30/install-ruby-and-vim-command-without-root/#disqus_thread"
             data-disqus-identifier="http://BobbyTang.github.io/blog/2014/05/30/install-ruby-and-vim-command-without-root/">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>This post intend to write down the step for installing ruby and vim command line tools, without root access.
In addition, ncurses is the prerequisities of installing ruby and vim. Also, please install ruby first in order to enable rubyinterp.</p>

<ol>
<li>download ncurses</li>
<li><code>tar xvf ncurses-5.9.tar.gz</code></li>
<li>sh <code>./configure --prefix=/home/bobby/tools/ncurses ##--with-shared</code></li>
<li><code>make</code></li>
<li><code>make install</code></li>
<li>download ruby</li>
<li>sh <code>./configure --prefix=/home/bobby/tools/ruby1.9 --with-tlib=ncurses</code></li>
<li><code>make</code></li>
<li><code>make install</code></li>
<li>download from vim</li>
<li><code>bzip2 -cd vimxxx.tar.bz2 | tar xvf -</code></li>
<li>edit .bash_profile <code>set CPPLAGS="-I/home/bobby/tools/ncurses/include" LDFLAGS="-L/home/bobby/tools/ncurses/lib" export CPPFLAGS LDFLAGS</code></li>
<li>sh <code>./configure --prefix=/home/bobby/tools/vim7.4 --disable-selinux --enbale-gui=no --without-x --disable-gpm --disable-nls --with-tilib=ncurses --enable-multibyte --enable-rubyinterp --enable-perlinterp --enable-pythoninterp</code></li>
<li><code>make</code></li>
<li><code>make install</code></li>
<li>edit ~/.bashrc <code>alias vim="/home/bobby/tools/vim7.4/bin/vim"</code></li>
<li>edit ~/.vimrc <code>set synatx on set nocompatible set backspace=2</code></li>
<li>setup vimruntime in order to let vim find the syntax env, please edit .bash_profile <code>export VIMRUNTIME=/home/bobby/tools/preinstall/vim74/runtime</code></li>
</ol>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2014/05/21/java-performance-os-monitoring/">Java Performance - OS Monitoring</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-05-21T00:16:37+08:00" pubdate data-updated="true">May 21<span>st</span>, 2014</time>
        
           | <a href="/blog/2014/05/21/java-performance-os-monitoring/#disqus_thread"
             data-disqus-identifier="http://BobbyTang.github.io/blog/2014/05/21/java-performance-os-monitoring/">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><h2>Bottom Up Approach</h2>

<p>Bottom up begins at the lowest level of the software stack, at the CPU level looking at statistics such as CPU cache misses, inefficient use of CPU instructions, and then working up the software stack at what constructs or idioms are used by the application.</p>

<h2>Choosing the Right CPU Architecture</h2>

<p>One of the major design points behind the SPARC T-series processors is to address CPU cache misses by introducing multiple hardware threads per core.</p>

<h2>CPU Utilization</h2>

<p>A system with a single CPU socket with a quad core processor with hyperthreading disabled will show four CPUs in the GNOME System Monitor and report four virtual processors using the Java API Runtime.availableProcessors().</p>

<pre><code>xosview
vmstat
mpstat
top 
</code></pre>

<p>Which java thread is consuming CPU?</p>

<pre><code>jstack
</code></pre>

<h2>Monitoring Linux CPU Scheduler Run Queue</h2>

<pre><code>vmstat
</code></pre>

<h2>Memory Utilization</h2>

<pre><code>top
/proc/meminf
</code></pre>

<p>However, the following vmstat output from a Linux system illustrates a system that is experiencing swapping.  P36</p>

<h2>Monitoring Lock Contention on Linux</h2>

<pre><code>pidstat -w -I -p 9391 5
</code></pre>

<p>Hence, 3500 divided by 2, the num- ber of virtual processors = 1750. 1750 * 80,000 = 140,000,000. The number of clock cycles in 1 second on a 3.0GHz processor is 3,000,000,000. Thus, the percentage of clock cycles wasted on context switches is 140,000,000/3,000,000,000 = 4.7%.</p>

<p>The cost of a voluntary context switch at a processor clock cycle level is an expensive operation, generally upwards of about 80,000 clock cycles.</p>

<p>Again applying the general guideline of 3% to 5% of clock cycles spent in voluntary context switches implies a Java application that may be suffering from lock contention.</p>

<h2>Quick Lock Contention Monitoring</h2>

<h2>Isolating Hot Locks</h2>

<p>A common practice to find contended locks in a Java application has been to periodically take thread dumps and look for threads that tend to be blocked on the same lock across several thread dumps.</p>

<h2>Monitoring Involuntary Context Switches</h2>

<p>In contrast to voluntary context switching where an executing thread voluntarily takes itself off the CPU, involun- tary thread context switches occur when a thread is taken off the CPU as a result of an expiring time quantum or has been preempted by a higher priority thread.</p>

<p>Involuntary context switches can also be monitored on Linux using <code>pidstat -w</code>. High involuntary context switches are an indication there are more threads ready to run than there are virtual processors available to run them. As a result it is common to observe a high run queue depth in vmstat, high CPU utilization, and a high number of migrations (migrations are the next topic in this section) in conjunction with a large number of involuntary context switches.</p>

<p>On Linux, creation of processor sets and assigning applications to those processor sets can be accomplished using the Linux <code>taskset</code> command.</p>

<h2>Monitoring Thread Migrations</h2>

<p>As a general guideline, Java applications scaling across multiple cores or virtual processors and observing migrations greater than 500 per second could benefit from binding Java applications to processor sets.</p>

<h2>Network I/O Utilization</h2>

<pre><code>netstat -i 
nicstat
</code></pre>

<h2>Disk I/O Utilization</h2>

<pre><code>iostat -xm
</code></pre>

<p>One of the challenges with monitoring disk I/O utilization is identifying which files are being read or written to and which application is the source of the disk activity.</p>

<p>At the application level any strategy to minimize disk activity will help such as reducing the number of read and write operations using buffered input and output streams or integrating a caching data structure into the application to reduce or eliminate disk interaction.</p>

<h2>Additional Command Line Tools</h2>

<pre><code>sar
</code></pre>

<h2>Monitoring CPU Utilization on SPARC T-Series Systems</h2>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2014/04/29/python-environment-setup/">Python Environment Setup</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-04-29T08:10:26+08:00" pubdate data-updated="true">Apr 29<span>th</span>, 2014</time>
        
           | <a href="/blog/2014/04/29/python-environment-setup/#disqus_thread"
             data-disqus-identifier="http://BobbyTang.github.io/blog/2014/04/29/python-environment-setup/">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Python is a script language, the main idea for learning python is to utilize python to create easy hands-on automation script on linux env instead of shell.</p>

<p>Here, list the steps to configure PyDev, an eclipse plugin, inside eclipse environment.</p>

<ol>
<li>Access PyDev webpage: <a href="http://pydev.org/manual_101_install.html">http://pydev.org/manual_101_install.html</a></li>
<li>Download PyDev certificate</li>
<li>cd %JAVA_HOME%/bin</li>
<li>Run command: keytool.exe -import -file C:/download/pydev_certificate.cer -keystore %JAVA_HOME%/jre/lib/security/cacerts</li>
<li>Input default JDK cacerts password: changeit</li>
<li>Certificate installment completed</li>
<li>Download eclipse plugin on marketplace, or mannually download it and extract into dropins directory like: (dropins/pydev/eclipse/&hellip;)</li>
<li>Edit eclipse.ini, convert -vm=&hellip; JDK must be 1.7</li>
<li>Access JPython webpage: <a href="https://wiki.python.org/jython/InstallationInstructions">https://wiki.python.org/jython/InstallationInstructions</a></li>
<li>Download Jython 2.5.4rc1 &ndash; Traditional Installer at link: <a href="http://jython.org/downloads.html">http://jython.org/downloads.html</a></li>
<li>Run command: java -jar jython_installer-2.5.2.jar &mdash;console</li>
<li>Configure JPython interceptor in PvDev eclipse plugin</li>
</ol>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2014/04/27/operating-system-concepts-io-system/">Operating System Concepts - IO System</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-04-27T17:43:57+08:00" pubdate data-updated="true">Apr 27<span>th</span>, 2014</time>
        
           | <a href="/blog/2014/04/27/operating-system-concepts-io-system/#disqus_thread"
             data-disqus-identifier="http://BobbyTang.github.io/blog/2014/04/27/operating-system-concepts-io-system/">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><h2>I/O Hardware</h2>

<p>The device communicates with the machine via a connection point, or <strong>port</strong> — for example, a serial port.</p>

<p>If devices use a common set of wires, the connection is called a bus. A <strong>bus</strong> is a set of wires and a rigidly defined protocol that specifies a set of messages that can be sent on the wires.</p>

<p>This figure shows a <strong>PCI bus</strong> (the common PC system bus) that connects the processor–memory subsystem to the fast devices and an expansion bus that connects relatively slow devices, such as the keyboard and serial and USB ports.</p>

<p><img src="https://farm8.staticflickr.com/7406/14029529882_f49ab52235_z.jpg" title="pcbus_structure.png" ></p>

<p>A <strong>controller</strong> is a collection of electronics that can operate a port, a bus, or a device. A serial-port controller is a simple device controller. It is a single chip (or portion of a chip) in the computer that controls the signals on the wires of a serial port.</p>

<p>By contrast, a <strong>SCSI bus controller</strong> is not simple. Because the SCSI protocol is complex, the SCSI bus controller is often implemented as a separate circuit board (or a host adapter) that plugs into the computer. It typically contains a processor, microcode, and some private memory to enable it to process the SCSI protocol messages.</p>

<h2>Polling &amp; Interrupts</h2>

<p>In many computer architectures, three CPU-instruction cycles are sufficient to poll a device: read a device register, logical–and to extract a status bit, and branch if not zero. But <strong>polling</strong> becomes inefficient when it is attempted repeatedly yet rarely finds a device to be ready for service, while other useful CPU processing remains undone.</p>

<p>The hardware mechanism that enables a device to notify the CPU is called an <strong>interrupt</strong>.</p>

<p>The basic interrupt mechanism works as follows. The CPU hardware has a wire called the <strong>interrupt-request line</strong> that the CPU senses after executing every instruction. When the CPU detects that a controller has asserted a signal on the interrupt-request line, the CPU performs a state save and jumps to the <strong>interrupt-handler routine</strong> at a fixed address in memory.</p>

<p>Another example is found in the implementation of system calls. Usually, a program uses library calls to issue system calls. The library routines check the arguments given by the application, build a data structure to convey the arguments to the kernel, and then execute a special instruction called a <strong>software interrupt</strong>, or <strong>trap</strong>.</p>

<h2>Direct Memory Access</h2>

<p>For a device that does large transfers, such as a disk drive, it seems wasteful to use an expensive general-purpose processor to watch status bits and to feed data into a controller register one byte at a time—a process termed <strong>programmed I/O (PIO)</strong>. Many computers avoid burdening the main CPU with PIO by offloading some of this work to a special-purpose processor called a <strong>direct-memory-access (DMA) controller</strong>.</p>

<p><img src="https://farm8.staticflickr.com/7340/14029558121_fb7debb6a5_z.jpg" title="DMA_transfer.png" ></p>

<h2>Blocking and Nonblocking I/O</h2>

<p>An alternative to a nonblocking system call is an asynchronous system call. An asynchronous call returns immediately, without waiting for the I/O to complete.</p>

<p>The difference between nonblocking and asynchronous system calls is that a nonblocking read() returns immediately with whatever data are available—the full number of bytes requested, fewer, or none at all. An asynchronous read() call requests a transfer that will be performed in its entirety but will complete at some future time.</p>

<p><img src="https://farm3.staticflickr.com/2927/14032739105_b20504ca80_z.jpg" title="syn_asyn_io.png" ></p>

<h2>Buffering</h2>

<p>A <strong>buffer</strong> is a memory area that stores data being transferred between two devices or between a device and an application.</p>

<p>Buffering is done for three reasons.
1. One reason is to cope with a speed mismatch between the producer and consumer of a data stream.
2. A second use of buffering is to provide adaptations for devices that have different data-transfer sizes.
3. A third use of buffering is to support <strong>copy semantics</strong> for application I/O.</p>

<p>With <strong>copy semantics</strong>, the version of the data written to disk is guaranteed to be the version at the time of the application system call, independent of any subsequent changes in the application’s buffer. A simple way in which the operating system can guarantee copy semantics is for the write() system call to copy the application data into a kernel buffer before returning control to the application. The disk write is performed from the kernel buffer, so that subsequent changes to the application buffer have no effect.</p>

<h2>Caching</h2>

<p>A <strong>cache</strong> is a region of fast memory that holds copies of data.</p>

<p>When the kernel receives a file I/O request, the kernel first accesses the buffer cache to see whether that region of the file is already available in main memory. If it is, a physical disk I/O can be avoided or deferred.</p>

<h2>Transforming I/O Requests to Hardware Operations</h2>

<p>The figure suggests that an I/O operation requires a great many steps that together consume a tremendous number of CPU cycles.</p>

<ol>
<li>A process issues a blocking read() system call to a file descriptor of a file that has been opened previously.</li>
<li>The system-call code in the kernel checks the parameters for correctness. In the case of input, if the data are already available in the buffer cache, the data are returned to the process, and the I/O request is completed.</li>
<li>Otherwise, a physical I/O must be performed. The process is removed from the run queue and is placed on the wait queue for the device, and the I/O request is scheduled. Eventually, the I/O subsystem sends the request to the device driver. Depending on the operating system, the request is sent via a subroutine call or an in-kernel message.</li>
<li>The device driver allocates kernel buffer space to receive the data and schedules the I/O. Eventually, the driver sends commands to the device controller by writing into the device-control registers.</li>
<li>The device controller operates the device hardware to perform the data transfer.</li>
<li>The driver may poll for status and data, or it may have set up a DMA transfer into kernel memory. We assume that the transfer is managed by a DMA controller, which generates an interrupt when the transfer completes.</li>
<li>The correct interrupt handler receives the interrupt via the interrupt- vector table, stores any necessary data, signals the device driver, and returns from the interrupt.</li>
<li>The device driver receives the signal, determines which I/O request has completed, determines the request’s status, and signals the kernel I/O subsystem that the request has been completed.</li>
<li>The kernel transfers data or return codes to the address space of the requesting process and moves the process from the wait queue back to the ready queue.</li>
<li>Moving the process to the ready queue unblocks the process. When the scheduler assigns the process to the CPU, the process resumes execution at the completion of the system call.</li>
</ol>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2014/04/27/operating-system-concepts-memorymapped-file/">Operating System Concepts - MemoryMapped File</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-04-27T17:18:34+08:00" pubdate data-updated="true">Apr 27<span>th</span>, 2014</time>
        
           | <a href="/blog/2014/04/27/operating-system-concepts-memorymapped-file/#disqus_thread"
             data-disqus-identifier="http://BobbyTang.github.io/blog/2014/04/27/operating-system-concepts-memorymapped-file/">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content">
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2014/04/23/todo-reading-book-list/">TODO Reading Book List</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-04-23T06:39:31+08:00" pubdate data-updated="true">Apr 23<span>rd</span>, 2014</time>
        
           | <a href="/blog/2014/04/23/todo-reading-book-list/#disqus_thread"
             data-disqus-identifier="http://BobbyTang.github.io/blog/2014/04/23/todo-reading-book-list/">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>List the title of the books with corresponding reference url, for those which begin with */** are highly recommended.</p>

<h2>Fundamental</h2>

<ol>
<li>**<a href="http://www.amazon.com/Introduction-Algorithms-Thomas-H-Cormen/dp/0262033844/ref=sr_1_1?ie=UTF8&amp;qid=1398206561" title="amazon">Introduction to Algorithms</a></li>
<li>*<a href="http://www.amazon.com/Operating-System-Concepts-Abraham-Silberschatz/dp/047050949X/ref=sr_1_1?ie=UTF8&amp;qid=1398206626" title="amazon">Operating System Concepts with Java</a></li>
</ol>


<h2>Java</h2>

<ol>
<li>**<a href="http://www.amazon.com/Thinking-Java-Edition-Bruce-Eckel/dp/0131872486/ref=sr_1_1?ie=UTF8&amp;qid=1398207134" title="amazon">Thinking in Java (4th Edition)</a> prefer to starting with collections&amp;container chapter</li>
<li>*<a href="http://www.amazon.com/Java-Performance-Charlie-Hunt/dp/0137142528/ref=sr_1_1?s=books&amp;ie=UTF8&amp;qid=1398207290" title="amazon">Java Performance</a></li>
<li><a href="http://www.amazon.com/Java-Nio-Ron-Hitchens/dp/0596002882/ref=sr_1_1?ie=UTF8&amp;qid=1398207507" title="amazon">Java Nio</a></li>
<li><a href="http://www.amazon.com/Java-Message-Service-David-Chappell-ebook/dp/B0026OR3JY/ref=sr_1_1?ie=UTF8&amp;qid=1398207629" title="amazon">Java Message Service</a></li>
</ol>


<h2>Shell</h2>

<h2>DataBase</h2>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2014/04/23/operating-system-concepts-virtualmemory/">Operating System Concepts - VirtualMemory</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-04-23T05:43:26+08:00" pubdate data-updated="true">Apr 23<span>rd</span>, 2014</time>
        
           | <a href="/blog/2014/04/23/operating-system-concepts-virtualmemory/#disqus_thread"
             data-disqus-identifier="http://BobbyTang.github.io/blog/2014/04/23/operating-system-concepts-virtualmemory/">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><h2>Demand Paging</h2>

<p>Loading the entire program into memory results in loading the executable code for all options, regardless of whether an option is ultimately selected by the user or not. An alternative strategy is to load pages only as they are needed. This technique is known as <strong>demand paging</strong> and is commonly used in virtual memory systems.</p>

<h2>Page Fault</h2>

<p>A page fault causes the following sequence to occur:</p>

<p><img src="https://farm6.staticflickr.com/5325/13952117776_754a2b4bda.jpg" title="Steps_in_handling_a_page_fault.png" ></p>

<ol>
<li>Trap to the operating system.</li>
<li>Save the user registers and process state.</li>
<li>Determine that the interrupt was a page fault.</li>
<li>Check that the page reference was legal and determine the location of the page on the disk.</li>
<li>Issue a read from the disk to a free frame:

<ol type="a">
<li>Wait in a queue for this device until the read request is serviced.</li>
<li>Wait for the device seek and/or latency time.</li>
<li>Begin the transfer of the page to a free frame.</li>
</ol>
</li>
<li>While waiting, allocate the CPU to some other user (CPU scheduling, optional).</li>
<li>Receive an interrupt from the disk I/O subsystem (I/O completed).</li>
<li>Save the registers and process state for the other user (if step 6 is executed).</li>
<li>Determine that the interrupt was from the disk.</li>
<li>Correct the page table and other tables to show that the desired page is now in memory.</li>
<li>Wait for the CPU to be allocated to this process again.</li>
<li>Restore the user registers, process state, and new page table, and then  resume the interrupted instruction.</li>
</ol>


<h2>Copy-on-Write</h2>

<p>Considering that many child processes invoke the exec() system call immediately after creation, the copying of the parent’s address space may be unnecessary.</p>

<p>Instead, we can use a technique known as <strong>copy-on-write</strong>, which works by allowing the parent and child processes initially to share the same pages. These shared pages are marked as copy-on-write pages, meaning that if either process writes to a shared page, a copy of the shared page is created.</p>

<h2>Page Replacement</h2>

<ol>
<li>Find the location of the desired page on the disk.</li>
<li>Find a free frame:

<ol type="a">
<li>If there is a free frame, use it.</li>
<li>If there is no free frame, use a page-replacement algorithm to select a victim frame.</li>
<li>Write the victim frame to the disk; change the page and frame tables accordingly.</li>
</ol>
</li>
<li>Read the desired page into the newly freed frame; change the page and frame tables.</li>
<li>Restart the user process.</li>
</ol>


<p><strong>Page Replacement Algorithm</strong></p>

<ul>
<li>FIFO Page Replacement</li>
<li>Optimal Page Replacement</li>
<li>LRU Page Replacement</li>
<li>LRU-Approximation Page Replacement</li>
<li>Additional-Reference-Bits Algorithm</li>
<li>Second-Chance Algorithm

<ol type="a">
<li> Enhanced Second-Chance Algorithm</li>
</ol>
</li>
<li>Counting-Based Page Replacement

<ol type="a">
<li> least-frequently-used (LFU) page-replacement algorithm</li>
<li> most-frequently-used (MFU) page-replacement algorithm</li>
</ol>
</li>
</ul>


<h2>Raw I/O</h2>

<p>Some operating systems give special programs the ability to use a disk partition as a large sequential array of logical blocks, without any file-system data structures. This array is sometimes called the raw disk, and I/O to this array is termed <strong>raw I/O</strong>.</p>

<p><strong>Raw I/O</strong> bypasses all the file- system services, such as file I/O demand paging, file locking, prefetching, space allocation, file names, and directories.</p>

<h2>Thrashing</h2>

<p>In fact, look at any process that does not have “enough” frames. If the process does not have the number of frames it needs to support pages in active use, it will quickly page-fault. At this point, it must replace some page. However, since all its pages are in active use, it must replace a page that will be needed again right away. Consequently, it quickly faults again, and again, and again, replacing pages that it must bring back in immediately.</p>

<p>This high paging activity is called <strong>thrashing</strong>. A process is thrashing if it is spending more time paging than executing.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2014/04/09/operating-system-concepts-mainmemory/">Operating System Concepts - MainMemory</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-04-09T07:39:27+08:00" pubdate data-updated="true">Apr 9<span>th</span>, 2014</time>
        
           | <a href="/blog/2014/04/09/operating-system-concepts-mainmemory/#disqus_thread"
             data-disqus-identifier="http://BobbyTang.github.io/blog/2014/04/09/operating-system-concepts-mainmemory/">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><h2>Contiguous Memory Allocation</h2>

<p>Problem:</p>

<p>Both the first-fit and best-fit strategies for memory allocation suffer from <strong>external fragmentation</strong>.</p>

<p>The general approach to avoiding this problem is to break the physical memory into fixed-sized blocks and allocate memory in units based on block size. With this approach, the memory allocated to a process may be slightly larger than the requested memory. The difference between these two numbers is <strong>internal fragmentation</strong> — unused memory that is internal to a partition.</p>

<p>Solution:</p>

<p>One solution to the problem of external fragmentation is <strong>compaction</strong>. The goal is to shuffle the memory contents so as to place all free memory together in one large block. Compaction is possible only if relocation is dynamic and is done at execution time.</p>

<p>Another possible solution to the external-fragmentation problem is to permit the logical address space of the processes to be noncontiguous, thus allowing a process to be allocated physical memory wherever such memory is available.</p>

<h2>Page and Segmentation</h2>

<p><strong>Paging</strong> is a memory-management scheme that permits the physical address space of a process to be noncontiguous. Paging avoids external fragmentation and the need for compaction.</p>

<p><img src="https://farm8.staticflickr.com/7454/13951470216_7af3187c5c.jpg" title="paging_with_TLB" ></p>

<p>The <strong>translation look-aside buffer(TLB)</strong> is associative, high-speed memory. Each entry in the TLB consists of two parts: a key (or tag) and a value. When the associative memory is presented with an item, the item is compared with all keys simultaneously. If the item is found, the corresponding value field is returned.</p>

<p>If the page number is not in the TLB (known as a <strong>TLB miss</strong>), a memory reference to the page table must be made. When the frame number is obtained, we can use it to access memory (Figure 8.11). In addition, we add the page number and frame number to the TLB, so that they will be found quickly on the next reference.</p>

<p><strong>Segmentation</strong> is a memory-management scheme that supports this user view of memory.</p>

<h2>Page Table</h2>

<ul>
<li>hierarchical paging</li>
</ul>


<p>Problem&amp;Solution:</p>

<p>For example, consider a system with a 32-bit logical address space. If the page size in such a system is 4 KB (212), then a page table may consist of up to 1 million entries (232/212). Assuming that each entry consists of 4 bytes, each process may need up to 4 MB of physical address space for the page table alone. Clearly, we would not want to allocate the page table contiguously in main memory. One simple solution to this problem is to divide the page table into smaller pieces. We can accomplish this division in several ways.</p>

<pre><code>$ getconf PAGESIZE
4096
</code></pre>

<ul>
<li>hashed page tables</li>
</ul>


<p>Problem&amp;Solution:</p>

<p>A common approach for handling address spaces larger than 32 bits is to use a <strong>hashed page table</strong>, with the hash value being the virtual page number.</p>

<ul>
<li>inverted page tables</li>
</ul>


<p>Problem&amp;Solution:</p>

<p>Usually, each process has an associated page table. One of the drawbacks of this method is that each page table may consist of millions of entries. These tables may consume large amounts of physical memory just to keep track of how other physical memory is being used.</p>

<p>Drawbacks:</p>

<p>Although this scheme decreases the amount of memory needed to store each page table, it increases the amount of time needed to search the table when a page reference occurs.</p>

<p>Systems that use inverted page tables have difficulty implementing shared memory. Shared memory is usually implemented as multiple virtual addresses (one for each process sharing the memory) that are mapped to one physical address. This standard method cannot be used with inverted page tables; because there is only one virtual page entry for every physical page, one physical page cannot have two (or more) shared virtual addresses.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2014/04/02/operating-system-concepts-cpu/">Operating System Concepts - CPU</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-04-02T06:30:57+08:00" pubdate data-updated="true">Apr 2<span>nd</span>, 2014</time>
        
           | <a href="/blog/2014/04/02/operating-system-concepts-cpu/#disqus_thread"
             data-disqus-identifier="http://BobbyTang.github.io/blog/2014/04/02/operating-system-concepts-cpu/">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><h2>CPU Scheduling</h2>

<p><strong>CPU scheduling</strong> is the task of selecting a waiting process from the ready queue and allocating the CPU to it. The CPU is allocated to the selected process by the dispatcher.</p>

<h2>Scheduling Criteria</h2>

<ul>
<li>CPU utilization</li>
<li>Throughput</li>
<li>Turnaround time</li>
</ul>


<p>The interval from the time of submission of a process to the time of completion is the turnaround time. <strong>Turnaround time</strong> is the sum of the periods spent waiting to get into memory, waiting in the ready queue, executing on the CPU, and doing I/O.</p>

<ul>
<li>Waiting time</li>
<li>Response time</li>
</ul>


<h2>Scheduling Alogrithm</h2>

<ul>
<li>First-Come, First-Served Scheduling</li>
<li>Shortest-Job-First Scheduling</li>
<li>Priority Scheduling</li>
</ul>


<p>A major problem with priority scheduling algorithms is <strong>indefinite blocking</strong>, or <strong>starvation</strong>.</p>

<p>A solution to the problem of indefinite blockage of low-priority processes is <strong>aging</strong>.</p>

<ul>
<li>Round-Robin Scheduling</li>
<li>Multilevel Queue Scheduling</li>
<li>Multilevel Feedback Queue Scheduling</li>
</ul>


<h2>Multiple-Processor/Multicore Scheduling</h2>

<ul>
<li>Processor Affinity</li>
</ul>


<p>Because of the high cost of invalidating and repopulating caches, most SMP systems try to avoid migration of processes from one processor to another and instead attempt to keep a process running on the same processor. This is known as <strong>processor affinity</strong>.</p>

<p>Some systems — such as Linux — also provide system calls that support hard affinity, thereby allowing a process to specify that it is not to migrate to other processors.</p>

<p>The main-memory architecture of a system can affect processor affinity issues. Recall the knowledge non-uniform memory access (NUMA) mentioned in previous post, in which a CPU has faster access to some parts of main memory than to other parts.</p>

<ul>
<li>Load Balancing</li>
</ul>


<p>Load balancing attempts to keep the workload evenly distributed across all processors in an SMP system. It is important to note that load balancing is typically only necessary on systems where each processor has its own private queue of eligible processes to execute.</p>

<p>There are two general approaches to load balancing: <strong>push migration</strong> and <strong>pull migration</strong>. Linux runs its load-balancing algorithm every 200 milliseconds (push migration) or whenever the run queue for a processor is empty (pull migration).</p>

<ul>
<li>Memory Stall</li>
</ul>


<p>Researchers have discovered that when a processor accesses memory, it spends a significant amount of time waiting for the data to become available. This situation, known as a <strong>memory stall</strong>, may occur for various reasons, such as a <strong>cache miss</strong> (accessing data that are not in cache memory).</p>

<ul>
<li>Virtualization</li>
</ul>


<p>The virtualization software presents one or more virtual CPUs to each of the virtual machines running on the system and then schedules the use of the physical CPUs among the virtual machines.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2014/03/25/operating-system-concepts-process-slash-thread/">Operating System Concepts - Process/Thread</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-03-25T05:57:31+08:00" pubdate data-updated="true">Mar 25<span>th</span>, 2014</time>
        
           | <a href="/blog/2014/03/25/operating-system-concepts-process-slash-thread/#disqus_thread"
             data-disqus-identifier="http://BobbyTang.github.io/blog/2014/03/25/operating-system-concepts-process-slash-thread/">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><h2>Process Control Block</h2>

<p><strong>Process Control Block</strong> (PCB, also called Task Controlling Block, Task Struct, or Switchframe) is a data structure in the operating system kernel containing the information needed to manage a particular process.</p>

<p>Process state. The state may be new, ready, running, waiting, halted, and so on.</p>

<p>Program counter. The counter indicates the address of the next instruction to be executed for this process.</p>

<p>CPU registers. They include accumulators, index registers, stack pointers, and general-purpose registers, plus any condition-code information. Along with the program counter, this state information must be saved when an interrupt occurs, to allow the process to be continued correctly afterward.</p>

<p>CPU-scheduling information. This information includes a process priority, pointers to scheduling queues, and any other scheduling parameters.</p>

<p>Memory-management information. This information may include such information as the value of the base and limit registers, the page tables, or the segment tables, depending on the memory system used by the operating system.</p>

<p>Accounting information. This information includes the amount of CPU and real time used, time limits, account numbers, job or process numbers, and so on.</p>

<p>I/O status information. This information includes the list of I/O devices allocated to the process, a list of open files, and so on.</p>

<h2>Context Switch</h2>

<p>A <strong>context switch</strong> (also sometimes referred to as a process switch or a task switch) is the switching of the CPU (central processing unit) from one process or thread to another.</p>

<p>A <strong>context</strong> is the contents of a CPU&rsquo;s registers and program counter at any point in time.</p>

<p>A <strong>program counter</strong> is a specialized register that indicates the position of the CPU in its instruction sequence and which holds either the address of the instruction being executed or the address of the next instruction to be executed, depending on the specific system.</p>

<p>Context switching can be described in slightly more detail as the kernel (i.e., the core of the operating system) performing the following activities with regard to processes (including threads) on the CPU:</p>

<ol>
<li><p>suspending the progression of one process and storing the CPU&rsquo;s state (i.e., the context) for that process somewhere in memory,</p></li>
<li><p>retrieving the context of the next process from memory and restoring it in the CPU&rsquo;s registers and</p></li>
<li><p>returning to the location indicated by the program counter (i.e., returning to the line of code at which the process was interrupted) in order to resume the process.</p></li>
</ol>


<h3>When to switch?</h3>

<p>Context switches can occur only in kernel mode.</p>

<p><strong>Multitasking</strong> 1.)Preemptive schedulers often configure a timer interrupt to fire when a process exceeds its time slice. 2.)This context switch can be triggered by the process making itself unrunnable, such as by waiting for an I/O or synchronization operation to complete.</p>

<p><strong>Interrupt handling</strong> 1.) Hardware interrupt</p>

<p><strong>User and kernel mode switching</strong> may cause context switch.</p>

<h2>Multithread programing</h2>

<p>Benifits 1.) Responsiveness 2.)Resource sharing 3.) Economy 4.)Scalability</p>

<h2>Multicore Programming</h2>

<p>Concerns 1.) Dividing activities 2.)Balance Data splitting 3.)Data dependency 4.)Testing and debugging</p>

<h2>Multithread Model</h2>

<ul>
<li>Many-to-one model</li>
<li>One-to-one model</li>
</ul>


<p>The nptl(native posix thread library) implementation only uses a 1:1 thread model. The scheduler handles every thread as if it were a process. Therefore only the supported scope is PTHREAD_SCOPE_SYSTEM(Plesae see on Pthread Scheduling label). The default scheduling policy is SCHED_OTHER, which is the default Linux scheduler. The nptl implementation can utilize multiple CPUs.</p>

<ul>
<li>Many-to-many model</li>
<li>Green thread</li>
</ul>


<p>On multi-CPU machines, native threads can run more than one thread simultaneously by assigning different threads to different CPUs. Green threads run on only one CPU.</p>

<p>Green threads, the threads provided by the JVM, run at the user level, meaning that the JVM creates and schedules the threads itself. Therefore, the operating system kernel doesn&rsquo;t create or schedule them. Instead, the underlying OS sees the JVM only as one thread.</p>

<ul>
<li>Light weight process(LWP)
In the traditional meaning of the term, as used in Unix System V and Solaris, a LWP runs in user space on top of a single kernel thread and shares its address space and system resources with other LWPs within the same process.</li>
</ul>


<h2>Pthread Scheduling</h2>

<p>There are two possible contention scopes. PTHREAD_SCOPE_SYSTEM and PTHREAD_SCOPE_PROCESS. They can be set with pthread_attr_setscope(). The scope of a thread can only be specified before the thread is created.</p>

<ul>
<li>PTHREAD_SCOPE_SYSTEM</li>
</ul>


<p>A thread that has a scope of PTHREAD_SCOPE_SYSTEM will content with other processes and other PTHREAD_SCOPE_SYSTEM threads for the CPU.</p>

<ul>
<li>PTHREAD_SCOPE_PROCESS</li>
</ul>


<p>All threads of a process that have a scope of PTHREAD_SCOPE_PROCESS will be grouped together and this group of threads contents for the CPU. If there is a process with 4 PTHREAD_SCOPE_PROCESS threads and 4 PTHREAD_SCOPE_SYSTEM threds, then each of the PTHREAD_SCOPE_SYSTEM threads will get a fifth of the CPU and the other 4 PTHREAD_SCOPE_PROCESS threads will share the remaing fifth of the CPU. How the PTHREAD_SCOPE_PROCESS threads share their fifth of the CPU among themselves is determined by the scheduling policy and the thread&rsquo;s priority.</p>

<h2>Process Creation</h2>

<p>When a process creates a new process, two possibilities exist in terms of execution:</p>

<ol>
<li>The parent continues to execute concurrently with its children.</li>
<li>The parent waits until some or all of its children have terminated.</li>
</ol>


<p>There are also two possibilities in terms of the address space of the new process:</p>

<ol>
<li>The child process is a duplicate of the parent process (it has the same program and data as the parent).</li>
<li>The child process has a new program loaded into it.</li>
</ol>


<p>For example, if <code>clone()</code> is passed the flags <code>CLONE FS</code>, <code>CLONE VM</code>, <code>CLONE SIGHAND</code>, and <code>CLONE FILES</code>, the parent and child tasks will share the same file-system information (such as the current working directory), the same memory space, the same signal handlers, and the same set of open files.</p>

<p>However, if none of these flags is set when <code>clone()</code> is invoked, no sharing takes place, resulting in functionality similar to that provided by the <code>fork()</code> system call.</p>
</div>
  
  


    </article>
  
  <div class="pagination">
    
      <a class="prev" href="/blog/page/2/">&larr; Older</a>
    
    <a href="/blog/archives">Blog Archives</a>
    
  </div>
</div>
<aside class="sidebar">
  
    <section>
  <h1>Categories</h1>
  <ul id="categories">
    <li class='category'><a href='/blog/categories/devenvsetup/'>DevEnvSetup (2)</a></li>
<li class='category'><a href='/blog/categories/python/'>Python (1)</a></li>
<li class='category'><a href='/blog/categories/ruby/'>Ruby (1)</a></li>
<li class='category'><a href='/blog/categories/books/'>books (8)</a></li>
<li class='category'><a href='/blog/categories/sql/'>sql (2)</a></li>
<li class='category'><a href='/blog/categories/test/'>test (1)</a></li>

  </ul>
</section>
<section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2014/05/30/install-ruby-and-vim-command-without-root/">Install Ruby&amp;Vim Command Without Root</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/05/21/java-performance-os-monitoring/">Java Performance - OS Monitoring</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/04/29/python-environment-setup/">Python Environment Setup</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/04/27/operating-system-concepts-io-system/">Operating System Concepts - IO System</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/04/27/operating-system-concepts-memorymapped-file/">Operating System Concepts - MemoryMapped File</a>
      </li>
    
  </ul>
</section>





  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2014 - BobbyTang -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  

<script type="text/javascript">
      var disqus_shortname = 'bobbytang';
      
        
        var disqus_script = 'count.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>











</body>
</html>
